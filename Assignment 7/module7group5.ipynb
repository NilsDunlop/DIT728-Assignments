{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7365d49bc45f1",
   "metadata": {
    "id": "b0e7365d49bc45f1"
   },
   "source": [
    "# Group 5 - Module 7: Dialogue systems and question answering\n",
    "\n",
    "***\n",
    "### Group Members:\n",
    "* **Nils Dunlop, 20010127-2359, Applied Data Science, e-mail: gusdunlni@student.gu.se (15 hours)**\n",
    "* **Francisco Erazo, 19930613-9214, Applied Data Science, e-mail: guserafr@student.gu.se (15 hours)**\n",
    "\n",
    "#### **We hereby declare that we have both actively participated in solving every exercise. All solutions are entirely our own work, without having taken part of other solutions.\" (This is independent and additional to any declaration that you may encounter in the electronic submission system.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ce4f1465244c7",
   "metadata": {
    "id": "a40ce4f1465244c7"
   },
   "source": [
    "# Assignment 7\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426429e48a4209ce",
   "metadata": {
    "id": "426429e48a4209ce"
   },
   "source": [
    "## Problem 1: Reading and Summary\n",
    "***\n",
    "\n",
    "The paper describes the development and functionality of GUS (Genial Understander System), a dialogue-based system designed primarily to simulate a travel agent's role for booking return trips within California. The system's main objective is to process and understand English dialogues, showcasing its capacity to manage various elements of natural conversation. These include handling shifts in initiative, interpreting indirect responses, resolving anaphora or expressions, and understanding conversational implicates.\n",
    "\n",
    "GUS's architecture is modular, integrating multiple components such as morphological and syntactic analyzers and a frame reasoner. This structure allows it to execute dialogues efficiently through procedural attachment and scheduling techniques. The paper highlights the system's innovative approach to dialogue management, demonstrating its potential for understanding and generating human-like conversations within its specified domain.\n",
    "\n",
    "Despite its advancements, the paper also discusses GUS's limitations and emphasizes the complexity of achieving realistic dialogue interactions, especially at the time of its publication in 1976. It points out the necessity for more sophisticated knowledge representation and reasoning capabilities to improve the system's performance. The development of GUS marks a significant step in the field of language understanding systems, illustrating both the potential and challenges of creating machines capable of engaging in meaningful dialogues with humans. Through its frame-driven design, GUS contributes to the ongoing research in artificial intelligence, particularly in natural language processing and understanding, setting a foundation for future improvements and innovations in the area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6dbabbbd02376",
   "metadata": {
    "id": "b1b6dbabbbd02376"
   },
   "source": [
    "## Problem 2: Implement A Simple Dialogue System\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 a) Implement a simple text-based digital assistant that can help with at least three things"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13eda0a90a449726"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "import requests\n",
    "import base64\n",
    "from datetime import datetime\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Define the digital assistant class\n",
    "class DigitalAssistant:\n",
    "    def __init__(self, intents):\n",
    "        self.nlp = spacy.load(\"en_core_web_md\")\n",
    "        self.intents = intents\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "        self.setup_matcher()\n",
    "        self.intent_handlers = {\n",
    "            \"WEATHER\": self.handle_weather,\n",
    "            \"RESTAURANT\": self.handle_restaurant,\n",
    "            \"TRAM\": self.handle_tram\n",
    "        }\n",
    "        self.intent_docs = {\n",
    "            intent: [self.nlp(phrase) for phrase in phrases]\n",
    "            for intent, phrases in self.intents.items()\n",
    "        }\n",
    "\n",
    "    def setup_matcher(self):\n",
    "        # Add match patterns for entity recognition\n",
    "        weather_patterns = [[{\"LOWER\": \"weather\"}], [{\"LOWER\": \"forecast\"}], [{\"LOWER\": \"temperature\"}]]\n",
    "        restaurant_patterns = [[{\"LOWER\": \"eat\"}], [{\"LOWER\": \"restaurant\"}], [{\"LOWER\": \"food\"}]]\n",
    "        tram_patterns = [[{\"LOWER\": \"tram\"}], [{\"LOWER\": \"bus\"}], [{\"LOWER\": \"schedule\"}], [{\"LOWER\": \"next\"}]]\n",
    "        for pattern in weather_patterns:\n",
    "            self.matcher.add(\"WEATHER\", [pattern])\n",
    "        for pattern in restaurant_patterns:\n",
    "            self.matcher.add(\"RESTAURANT\", [pattern])\n",
    "        for pattern in tram_patterns:\n",
    "            self.matcher.add(\"TRAM\", [pattern])\n",
    "\n",
    "    def determine_context(self, user_input):\n",
    "        doc = self.nlp(user_input)\n",
    "        matches = self.matcher(doc)\n",
    "\n",
    "        if matches:\n",
    "            for match_id, start, end in matches:\n",
    "                span = doc[start:end]\n",
    "                intent = self.nlp.vocab.strings[match_id]\n",
    "                handler = self.intent_handlers.get(intent)\n",
    "\n",
    "                if handler:\n",
    "                    response = handler(user_input)\n",
    "                    return response\n",
    "        else:\n",
    "            clarification_message = (\n",
    "                \"I'm not sure what you're asking for. \"\n",
    "                \"I specialize in weather forecasts, restaurant recommendations, and tram schedules. \"\n",
    "                \"Could you please specify what you need help with?\"\n",
    "            )\n",
    "            return clarification_message\n",
    "\n",
    "    def identify_intent(self, user_doc):\n",
    "        max_similarity = 0.0\n",
    "        best_intent = None\n",
    "        for intent, docs in self.intent_docs.items():\n",
    "            for doc in docs:\n",
    "                similarity = user_doc.similarity(doc)\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_intent = intent\n",
    "        return best_intent, max_similarity\n",
    "\n",
    "    def fetch_weather_forecast(self):\n",
    "        # Gothenburg latitude and longitude\n",
    "        latitude = \"57.7089\"\n",
    "        longitude = \"11.9746\"\n",
    "        url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            weather_description = data['current_weather']['weathercode']\n",
    "            temperature = data['current_weather']['temperature']\n",
    "            # You may need to map the weather code to a description\n",
    "            weather_description_text = self.map_weather_code_to_description(weather_description)\n",
    "            return f\"The current weather in Gothenburg is {weather_description_text} with a temperature of {temperature}°C.\"\n",
    "        else:\n",
    "            print(f\"Failed to fetch weather data: Status Code {response.status_code}, Response: {response.text}\")\n",
    "            return \"Sorry, I couldn't fetch the weather information right now.\"\n",
    "\n",
    "\n",
    "    def map_weather_code_to_description(self, code):\n",
    "        # Mapping based on WMO Weather interpretation codes\n",
    "        weather_code_mapping = {\n",
    "            0: \"clear sky\",\n",
    "            1: \"mainly clear\",\n",
    "            2: \"partly cloudy\",\n",
    "            3: \"overcast\",\n",
    "            45: \"fog\",\n",
    "            48: \"depositing rime fog\",\n",
    "            51: \"drizzle: light intensity\",\n",
    "            53: \"drizzle: moderate intensity\",\n",
    "            55: \"drizzle: dense intensity\",\n",
    "            56: \"freezing drizzle: light intensity\",\n",
    "            57: \"freezing drizzle: dense intensity\",\n",
    "            61: \"rain: slight intensity\",\n",
    "            63: \"rain: moderate intensity\",\n",
    "            65: \"rain: heavy intensity\",\n",
    "            66: \"freezing rain: light intensity\",\n",
    "            67: \"freezing rain: heavy intensity\",\n",
    "            71: \"snowfall: slight intensity\",\n",
    "            73: \"snowfall: moderate intensity\",\n",
    "            75: \"snowfall: heavy intensity\",\n",
    "            77: \"snow grains\",\n",
    "            80: \"rain showers: slight intensity\",\n",
    "            81: \"rain showers: moderate intensity\",\n",
    "            82: \"rain showers: violent intensity\",\n",
    "            85: \"snow showers: slight intensity\",\n",
    "            86: \"snow showers: heavy intensity\",\n",
    "            95: \"thunderstorm: slight or moderate\",\n",
    "            96: \"thunderstorm with slight hail\",\n",
    "            99: \"thunderstorm with heavy hail\",\n",
    "        }\n",
    "        # Handle compound codes by checking the presence of the code in a range\n",
    "        if code in weather_code_mapping:\n",
    "            return weather_code_mapping[code]\n",
    "        elif any(code in range_ for range_ in [(45, 48), (51, 55), (56, 57), (61, 65), (66, 67), (71, 75), (80, 82), (85, 86)]):\n",
    "            return weather_code_mapping[min(filter(lambda x: x >= code, weather_code_mapping))]\n",
    "        else:\n",
    "            return \"Unknown weather condition\"\n",
    "\n",
    "    def fetch_restaurant_recommendations(self, location=\"Gothenburg\", term=\"restaurants\", sort_by=\"rating\"):\n",
    "        api_key = \"k6g36lOU262KATfdkdn8eq1CxynKaupS4_pbvRLudUAZegBiUXVF6jy7gOOOHZmcb_gszKmK2-fK4Be5ggG4Ius1JVzqfXIcYmtzFY1D1anKIhkckj2SxjCZpq7lZXYx\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        params = {\n",
    "            \"location\": location,\n",
    "            \"term\": term,\n",
    "            \"sort_by\": sort_by,\n",
    "            \"limit\": 5\n",
    "        }\n",
    "    \n",
    "        # Yelp search endpoint\n",
    "        url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "    \n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            # Parse the JSON response\n",
    "            data = response.json()\n",
    "            businesses = data[\"businesses\"]\n",
    "    \n",
    "            # Create a list of restaurant names and their rating\n",
    "            restaurant_recommendations = [\n",
    "                f\"{business['name']} ({business['rating']} stars)\" for business in businesses\n",
    "            ]\n",
    "            return restaurant_recommendations\n",
    "        else:\n",
    "            print(f\"Failed to fetch restaurant data: Status Code {response.status_code}, Response: {response.text}\")\n",
    "            return \"Sorry, I couldn't fetch the restaurant information right now.\"\n",
    "\n",
    "    def get_vasttrafik_access_token(self, client_id, client_secret):\n",
    "        # Endpoint for the access token\n",
    "        token_url = \"https://ext-api.vasttrafik.se/token\"\n",
    "    \n",
    "        # Encode client ID and secret to base64 for the Authorization header\n",
    "        client_credentials = f\"{client_id}:{client_secret}\"\n",
    "        client_credentials_base64 = base64.b64encode(client_credentials.encode()).decode()\n",
    "    \n",
    "        # Headers\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "            \"Authorization\": f\"Basic {client_credentials_base64}\"\n",
    "        }\n",
    "    \n",
    "        # Body parameters\n",
    "        body = {\n",
    "            \"grant_type\": \"client_credentials\"\n",
    "        }\n",
    "    \n",
    "        # POST request to get the token\n",
    "        try:\n",
    "            response = requests.post(token_url, headers=headers, data=body)\n",
    "            response.raise_for_status()\n",
    "    \n",
    "            # If the request is successful, return the JSON response\n",
    "            return response.json()['access_token']\n",
    "        except requests.RequestException as e:\n",
    "            # Return a dictionary with an error message\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def get_stop_id(self, stop_name, access_token):\n",
    "        url = f\"https://ext-api.vasttrafik.se/pr/v4/locations/by-text?q={stop_name}&types=stoparea&limit=10&offset=0\"\n",
    "        headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            stop_id = data['results'][0]['gid']\n",
    "            return stop_id\n",
    "        else:\n",
    "            print(f\"Failed to fetch stop ID: {response.status_code}, {response.text}\")\n",
    "            return None\n",
    "\n",
    "    def fetch_tram_schedule(self, stop_name):\n",
    "        # Obtain the access token\n",
    "        access_token = self.get_vasttrafik_access_token(client_id='t6k4WYN9W93dzrH7ffXo7ZQqruwa', client_secret='0J3e7bwhB01lW33ffdZnanODTVYa')\n",
    "        if not access_token:\n",
    "            return \"Could not obtain access token.\"\n",
    "\n",
    "        # Get the stop ID for the given stop name\n",
    "        stop_id = self.get_stop_id(stop_name, access_token)\n",
    "        if not stop_id:\n",
    "            return f\"Could not find stop ID for {stop_name}.\"\n",
    "\n",
    "        # Fetch the tram schedule using the stop ID and access token\n",
    "        url = f\"https://ext-api.vasttrafik.se/pr/v4/stop-areas/{stop_id}/departures?timeSpanInMinutes=60&maxDeparturesPerLineAndDirection=2&limit=3&offset=0&includeOccupancy=false\"\n",
    "        headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            departures = data['results']\n",
    "            top_departures = departures[:3]\n",
    "\n",
    "            schedule = []\n",
    "            for d in top_departures:\n",
    "                estimated_time_str = d['estimatedTime']\n",
    "                if '.' in estimated_time_str:\n",
    "                    # Truncate the milliseconds\n",
    "                    estimated_time_str = estimated_time_str[:estimated_time_str.rindex('.')+7]\n",
    "                estimated_time = datetime.fromisoformat(estimated_time_str)\n",
    "                readable_time = estimated_time.strftime('%H:%M:%S')\n",
    "\n",
    "                # Add the departure to the schedule list\n",
    "                line_info = f\"{d['serviceJourney']['line']['name']} to {d['serviceJourney']['direction']}\"\n",
    "                schedule_info = f\"{line_info} departs at {readable_time}\"\n",
    "                schedule.append(schedule_info)\n",
    "\n",
    "            return schedule\n",
    "        else:\n",
    "            print(f\"Failed to fetch tram schedule: {response.status_code}, {response.text}\")\n",
    "            return \"Sorry, I couldn't fetch the tram schedule right now.\"\n",
    "\n",
    "    def handle_weather(self, user_input):\n",
    "        doc = self.nlp(user_input)\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            if self.nlp.vocab.strings[match_id] == \"WEATHER\":\n",
    "                forecast = self.fetch_weather_forecast()\n",
    "                if forecast:\n",
    "                    return f\"You asked about the {span.text}. {forecast}\"\n",
    "        return \"I'm sorry, I didn't understand your weather question. Can you ask differently?\"\n",
    "\n",
    "    def handle_restaurant(self, user_input):\n",
    "        doc = self.nlp(user_input)\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            span = doc[start:end]\n",
    "            if self.nlp.vocab.strings[match_id] == \"RESTAURANT\":\n",
    "                recommendations = self.fetch_restaurant_recommendations()\n",
    "                if recommendations:\n",
    "                    return f\"Looking for a place to {span.text}? Here are some suggestions: {', '.join(recommendations)}\"\n",
    "        return \"I'm sorry, I didn't catch what type of restaurant you're looking for.\"\n",
    "\n",
    "    def handle_tram(self, user_input):\n",
    "        doc = self.nlp(user_input)\n",
    "        matches = self.matcher(doc)\n",
    "        stop_name = None\n",
    "        # Extract stop name if mentioned \n",
    "        # Otherwise default to 'Brunnsparken'\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"GPE\" or ent.label_ == \"LOC\":\n",
    "                stop_name = ent.text\n",
    "                break\n",
    "        stop_name = stop_name if stop_name else 'Brunnsparken'\n",
    "        schedule = self.fetch_tram_schedule(stop_name)\n",
    "        if schedule:\n",
    "            return f\"The next trams from {stop_name} are: {'; '.join(schedule)}\"\n",
    "        else:\n",
    "            return \"I'm sorry, I couldn't find the tram schedule right now.\"\n",
    "\n",
    "    def get_response(self, user_input):\n",
    "        # Calls determine_context to process the input\n",
    "        return self.determine_context(user_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T18:38:58.583292100Z",
     "start_time": "2024-03-04T18:38:54.942174700Z"
    }
   },
   "id": "68b4c60668b85a0b",
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked about the weather. The current weather in Gothenburg is clear sky with a temperature of 4.2°C.\n",
      "Looking for a place to eat? Here are some suggestions: Samui Thai Express (5.0 stars), Trattoria La Strega (5.0 stars), Tre Små Rum (4.9 stars), Swedish Taste (4.8 stars), Fiskekrogen (4.8 stars)\n",
      "The next trams from Brunnsparken are: Spårvagn 1 to Östra Sjukhuset departs at 19:38:00; Spårvagn 10 to Brämaregården departs at 19:38:00; Buss 16 to Högsbohöjd departs at 19:39:00\n"
     ]
    }
   ],
   "source": [
    "# Initialize the assistant with intents\n",
    "intents = {\n",
    "    \"weather\": [\"What's the weather like?\", \"Tell me the weather forecast\", \"Is it going to rain today?\"],\n",
    "    \"restaurant\": [\"Find me a place to eat\", \"I want to order food\", \"Recommend a restaurant\"],\n",
    "    \"tram\": [\"When is the next tram?\", \"Tram schedule\", \"How often does the bus run?\"],\n",
    "}\n",
    "assistant = DigitalAssistant(intents)\n",
    "\n",
    "# Sample user input processing\n",
    "print(assistant.get_response(\"What's the weather like today?\"))\n",
    "print(assistant.get_response(\"I'm looking for a place to eat.\"))\n",
    "print(assistant.get_response(\"When is the next tram from Brunnsparken?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T18:39:02.823449500Z",
     "start_time": "2024-03-04T18:38:58.582284400Z"
    }
   },
   "id": "b3f2406043d6bf30",
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    "As per the assignment description, we designed a simple text-based digital assistant capable of performing three primary functions (as seen above):\n",
    "1. Providing weather forecasts\n",
    "2. Finding restaurants\n",
    "3. Finding tram/bus schedules\n",
    "\n",
    "### Approach and Design\n",
    "\n",
    "The assistant is built using Python with the Spacy library for natural language processing (NLP) and the Requests library for handling API requests. The core functionalities are achieved through the integration of various APIs, including Open-Meteo for weather forecasts and Yelp Fusion for restaurant recommendations. The Västtrafik public transport API is used for tram and bus schedules in Gothenburg. We decided to focus on Gothenburg to reduce the complexity of the system and to make it easier to test and verify the results.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "- **Spacy NLP**: Utilized for processing user input and identifying the context of queries based on keyword matching.\n",
    "- **Matcher**: A Spacy Matcher object is used to define patterns for recognizing keywords related to weather, restaurants, and tram/bus schedules.\n",
    "- **API Integration**: Requests are made to external APIs to fetch real-time data for weather, restaurant, and tram/bus schedule information.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "1. **Intent Recognition**: The digital assistant uses Spacy's Matcher to identify the user's intent based on predefined patterns. This allows for a flexible dialogue system that can understand variations in how users may request information.\n",
    "\n",
    "2. **Dynamic Response Handling**: Based on the identified intent, the assistant dynamically selects the appropriate handler function to process the request and fetch the relevant information.\n",
    "\n",
    "3. **Extensibility**: The architecture of the assistant is designed to be easily extensible. New intents and handler functions can be added to the `intent_handlers` dictionary without modifying the core logic of the assistant.\n",
    "\n",
    "### Sample Outputs\n",
    "\n",
    "The assistant can process queries like:\n",
    "\n",
    "- \"What's the weather like today?\"\n",
    "- \"I'm looking for a place to eat.\"\n",
    "- \"When is the next tram from Brunnsparken?\"\n",
    "\n",
    "For each query, it identifies the intent, calls the corresponding handler, and returns information fetched from the respective API."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1ed00f1122a7d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 b) Suggest how - if more time were available - you could make your dialogue system more advanced\n",
    "***\n",
    "### Limitations\n",
    "\n",
    "- **Keyword Dependency**: The current implementation relies heavily on keyword matching for intent recognition, which may not capture the full nuance of user queries.\n",
    "- **Static Patterns**: The patterns used for matching are predefined and static, which may limit the assistant's ability to understand varied or complex queries.\n",
    "- **Error Handling**: The system's response to unrecognized queries or API failures could be improved to provide more helpful feedback to the user.\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "- **Machine Learning Models**: Incorporating machine learning models for intent recognition could significantly improve the assistant's understanding of user queries.\n",
    "- **Dynamic Pattern Matching**: Implementing a system for dynamically generating or updating patterns based on user interactions could enhance the assistant's flexibility.\n",
    "- **User Feedback Loop**: Integrating a feedback mechanism to learn from user interactions and refine responses over time.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This digital assistant demonstrates the basic principles of designing an AI-powered dialogue system. While the current implementation provides a foundation, there's ample scope for incorporating advanced NLP techniques and machine learning models to create a more sophisticated and intuitive assistant. With more time and resources, the system could be enhanced to handle a wider range of user queries and provide more accurate and context-aware responses."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfec727bb093b591"
  },
  {
   "cell_type": "markdown",
   "id": "88753424",
   "metadata": {},
   "source": [
    "## References\n",
    "***\n",
    "\n",
    "- Hyperskill. (2024). Rule-based dialogue systems | Question Answering | Main NLP tasks | NLP | Data science | Computer science | Hyperskill. [online] Available at: https://hyperskill.org/learn/step/30059 [Accessed 4 Mar. 2024].\n",
    "\n",
    "- Hyperskill. (2024). Rule-based dialogue systems | Question Answering | Main NLP tasks | NLP | Data science | Computer science | Hyperskill. [online] Available at: https://hyperskill.org/learn/step/30059 [Accessed 4 Mar. 2024].\n",
    "\n",
    "- Mondal, A. (2021). How to Build Your AI Chatbot with NLP in Python? [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2021/10/complete-guide-to-build-your-ai-chatbot-with-nlp-in-python/ [Accessed 4 Mar. 2024]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c902e53e01be6b5",
   "metadata": {
    "id": "3c902e53e01be6b5"
   },
   "source": [
    "## Self Check\n",
    "***\n",
    "- Have you answered all questions to the best of your ability?\n",
    "Yes, we have.\n",
    "- Is all the required information on the front page, is the file name correct etc.?\n",
    "Indeed, all the required information on the front page has been included.\n",
    "- Anything else you can easily check? (details, terminology, arguments, clearly stated answers etc.?)\n",
    "We have checked, and everything looks good."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
