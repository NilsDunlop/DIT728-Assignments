{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7365d49bc45f1",
   "metadata": {
    "id": "b0e7365d49bc45f1"
   },
   "source": [
    "# Group 5 - Module 6: Game Playing Systems\n",
    "\n",
    "***\n",
    "### Group Members:\n",
    "* **Nils Dunlop, 20010127-2359, Applied Data Science, e-mail: gusdunlni@student.gu.se (16 hours)**\n",
    "* **Francisco Erazo, 19930613-9214, Applied Data Science, e-mail: guserafr@student.gu.se (16 hours)**\n",
    "\n",
    "#### **We hereby declare that we have both actively participated in solving every exercise. All solutions are entirely our own work, without having taken part of other solutions.\" (This is independent and additional to any declaration that you may encounter in the electronic submission system.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ce4f1465244c7",
   "metadata": {
    "id": "a40ce4f1465244c7"
   },
   "source": [
    "# Assignment 6\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426429e48a4209ce",
   "metadata": {
    "id": "426429e48a4209ce"
   },
   "source": [
    "## Problem 1: Reading and Reflection\n",
    "***\n",
    "AlphaGo is a computer program designed to play the board game Go. It was created by DeepMind Technologies, now a part of Google. Go is known for its complex strategies and the vast number of possible moves, presenting a significant challenge for traditional AI methods. AlphaGo uses advanced deep neural networks and Monte Carlo Tree Search (MCTS), enabling it to learn from a large amount of data, including recorded games between human experts and games it played against itself. Through this learning process, AlphaGo developed judgment and intuition similar to human players, allowing it to accurately predict moves and game outcomes.\n",
    "\n",
    "The architecture of AlphaGo includes policy networks that suggest probable next moves, and value networks that predict the game's winner from any position, marking a step forward in using AI to tackle complex problems. Its training involved supervised learning from games played by human experts and reinforcement learning from self-play. This approach enabled the system to continuously refine its strategies and adjust to new challenges. The integration of MCTS with neural networks enabled efficient exploration and evaluation of possible moves, balancing between relying on known effective strategies and exploring new ones.\n",
    "\n",
    "AlphaGo's success was demonstrated by its 99.8% win rate against other Go programs and its historic victory over European Go champion Fan Hui 5-0, marking the first time a computer program defeated a professional human player in Go. Given Go's complexity compared to chess, this achievement was seen as a significant milestone in AI.\n",
    "\n",
    "The strategies employed by AlphaGo, and its implications, extend beyond just games. They showcase the potential of deep learning and reinforcement learning to address complex issues in various fields.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6dbabbbd02376",
   "metadata": {
    "id": "b1b6dbabbbd02376"
   },
   "source": [
    "## Problem 2: Implementation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [' ' for _ in range(9)]\n",
    "        self.current_winner = None\n",
    "        \n",
    "    def print_board(self):\n",
    "        for row in [self.board[i*3:(i+1)*3] for i in range(3)]:\n",
    "            print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "    def available_moves(self):\n",
    "        return [i for i, spot in enumerate(self.board) if spot == ' ']\n",
    "\n",
    "    def empty_squares(self):\n",
    "        return ' ' in self.board\n",
    "\n",
    "    def make_move(self, square, letter):\n",
    "        if self.board[square] == ' ':\n",
    "            self.board[square] = letter\n",
    "            if self.winner(square, letter):\n",
    "                self.current_winner = letter\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def winner(self, square, letter):\n",
    "        # Check row\n",
    "        row_ind = square // 3\n",
    "        row = self.board[row_ind*3:(row_ind + 1)*3]\n",
    "        if all([s == letter for s in row]):\n",
    "            return True\n",
    "        # Check column\n",
    "        col_ind = square % 3\n",
    "        column = [self.board[col_ind+i*3] for i in range(3)]\n",
    "        if all([s == letter for s in column]):\n",
    "            return True\n",
    "        # Check diagonals\n",
    "        if square % 2 == 0:\n",
    "            diagonal1 = [self.board[i] for i in [0, 4, 8]]\n",
    "            if all([s == letter for s in diagonal1]):\n",
    "                return True\n",
    "            diagonal2 = [self.board[i] for i in [2, 4, 6]]\n",
    "            if all([s == letter for s in diagonal2]):\n",
    "                return True\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T13:36:19.209111Z",
     "start_time": "2024-02-23T13:36:19.171110600Z"
    }
   },
   "id": "af4c446252702d12",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearchNode:\n",
    "    def __init__(self, game, parent=None, move=None):\n",
    "        self.game = deepcopy(game)\n",
    "        self.parent = parent\n",
    "        self.move = move\n",
    "        self.children = []\n",
    "        self.wins = 0\n",
    "        self.visits = 0\n",
    "        self.untried_actions = self.game.available_moves()\n",
    "        self.player_just_moved = 'O' if self.game.current_winner == 'X' else 'X'\n",
    "        \n",
    "    def UCB1(self, total_visits, cp=1.21):\n",
    "        if self.visits == 0:\n",
    "            return float('inf')\n",
    "        return self.wins / self.visits + cp * (np.sqrt(np.log(total_visits) / self.visits))\n",
    "    \n",
    "    def select_child(self):\n",
    "        total_visits = sum(child.visits for child in self.children)\n",
    "        return max(self.children, key=lambda c: c.UCB1(total_visits))\n",
    "\n",
    "    def expand(self):\n",
    "        move = self.untried_actions.pop()\n",
    "        new_game = deepcopy(self.game)\n",
    "        new_game.make_move(move, self.player_just_moved)\n",
    "        child_node = MonteCarloTreeSearchNode(new_game, parent=self, move=move)\n",
    "        self.children.append(child_node)\n",
    "        return child_node\n",
    "\n",
    "    def simulate(self):\n",
    "        current_simulation_game = deepcopy(self.game)\n",
    "        while current_simulation_game.empty_squares():\n",
    "            possible_moves = current_simulation_game.available_moves()\n",
    "            if not possible_moves:  # No moves left, game is a draw\n",
    "                break\n",
    "            move = np.random.choice(possible_moves)\n",
    "            player_to_move = 'O' if self.player_just_moved == 'X' else 'X'\n",
    "            current_simulation_game.make_move(move, player_to_move)\n",
    "            if current_simulation_game.current_winner:\n",
    "                break\n",
    "            self.player_just_moved = player_to_move\n",
    "\n",
    "        if current_simulation_game.current_winner == self.player_just_moved:\n",
    "            return 1\n",
    "        elif current_simulation_game.current_winner and current_simulation_game.current_winner != self.player_just_moved:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0  # Draw\n",
    "\n",
    "    def backpropagate(self, result):\n",
    "        self.visits += 1\n",
    "        self.wins += result if self.player_just_moved == 'O' else -result\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(-result)\n",
    "\n",
    "    def best_move(self, simulations_number=1000):\n",
    "        for _ in range(simulations_number):\n",
    "            node = self\n",
    "            while node.untried_actions == [] and node.children != []:\n",
    "                node = node.select_child()\n",
    "            if node.untried_actions != []:\n",
    "                node = node.expand()\n",
    "            result = node.simulate()\n",
    "            node.backpropagate(result)\n",
    "\n",
    "        return max(self.children, key=lambda c: c.visits).move"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T13:36:19.242109900Z",
     "start_time": "2024-02-23T13:36:19.225112800Z"
    }
   },
   "id": "b0ef4c4cd3915d54",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |\n",
      "|   |   |   |\n",
      "|   | X |   |\n",
      "Player X makes a move to square 7\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "| O | X |   |\n",
      "Player O makes a move to square 6\n",
      "|   |   |   |\n",
      "| X |   |   |\n",
      "| O | X |   |\n",
      "Player X makes a move to square 3\n",
      "|   |   | O |\n",
      "| X |   |   |\n",
      "| O | X |   |\n",
      "Player O makes a move to square 2\n",
      "|   |   | O |\n",
      "| X |   | X |\n",
      "| O | X |   |\n",
      "Player X makes a move to square 5\n",
      "|   | O | O |\n",
      "| X |   | X |\n",
      "| O | X |   |\n",
      "Player O makes a move to square 1\n",
      "|   | O | O |\n",
      "| X |   | X |\n",
      "| O | X | X |\n",
      "Player X makes a move to square 8\n",
      "|   | O | O |\n",
      "| X | O | X |\n",
      "| O | X | X |\n",
      "Player O makes a move to square 4\n",
      "Player O wins!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the game\n",
    "game = TicTacToe()\n",
    "\n",
    "# Set the starting player\n",
    "current_player = 'X'\n",
    "\n",
    "while game.empty_squares() and not game.current_winner:\n",
    "    # Create the root node for MCTS with the current game state\n",
    "    root = MonteCarloTreeSearchNode(game, move=None, parent=None)\n",
    "\n",
    "    # Find the best move using MCTS\n",
    "    best_move = root.best_move(simulations_number=10000)\n",
    "\n",
    "    # Make the move\n",
    "    game.make_move(best_move, current_player)\n",
    "\n",
    "    # Print the board state\n",
    "    game.print_board()\n",
    "    print(f\"Player {current_player} makes a move to square {best_move}\")\n",
    "\n",
    "    # Check for a winner\n",
    "    if game.current_winner:\n",
    "        print(f\"Player {current_player} wins!\")\n",
    "        break\n",
    "    elif not game.empty_squares():\n",
    "        print(\"The game is a draw!\")\n",
    "        break\n",
    "\n",
    "    # Switch player\n",
    "    current_player = 'O' if current_player == 'X' else 'X'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T13:36:27.630551800Z",
     "start_time": "2024-02-23T13:36:19.247115100Z"
    }
   },
   "id": "2fabb23f1ae97f91",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "88753424",
   "metadata": {},
   "source": [
    "## References\n",
    "***\n",
    "\n",
    "- Choudhary, A. (2018). Reinforcement Learning Guide: Solving the Multi-Armed Bandit Problem from Scratch in Python. [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2018/09/reinforcement-multi-armed-bandit-scratch-python/ [Accessed 23 Feb. 2024]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c902e53e01be6b5",
   "metadata": {
    "id": "3c902e53e01be6b5"
   },
   "source": [
    "## Self Check\n",
    "***\n",
    "- Have you answered all questions to the best of your ability?\n",
    "Yes, we have.\n",
    "- Is all the required information on the front page, is the file name correct etc.?\n",
    "Indeed, all the required information on the front page has been included.\n",
    "- Anything else you can easily check? (details, terminology, arguments, clearly stated answers etc.?)\n",
    "We have checked, and everything looks good."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
