{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e7365d49bc45f1",
   "metadata": {
    "id": "b0e7365d49bc45f1"
   },
   "source": [
    "# Group 5 - Module 5: Natural Language Processing\n",
    "\n",
    "***\n",
    "### Group Members:\n",
    "* **Nils Dunlop, 20010127-2359, Applied Data Science, e-mail: gusdunlni@student.gu.se (16 hours)**\n",
    "* **Francisco Erazo, 19930613-9214, Applied Data Science, e-mail: guserafr@student.gu.se (16 hours)**\n",
    "\n",
    "#### **We hereby declare that we have both actively participated in solving every exercise. All solutions are entirely our own work, without having taken part of other solutions.\" (This is independent and additional to any declaration that you may encounter in the electronic submission system.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ce4f1465244c7",
   "metadata": {
    "id": "a40ce4f1465244c7"
   },
   "source": [
    "# Assignment 5\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426429e48a4209ce",
   "metadata": {
    "id": "426429e48a4209ce"
   },
   "source": [
    "## Problem 1: Reading and Reflection\n",
    "***\n",
    "### **(A) AI Problems with a Wide Range of Approaches:**\n",
    "\n",
    "Several AI problems have seen a similarly wide array of approaches, reflecting the many computational techniques utilized over the decades. Some notable examples include:\n",
    "- **Speech Recognition:** From early phonetic-based systems to modern deep learning approaches, speech recognition has evolved significantly. Early systems relied on simple pattern matching and rule-based systems to understand spoken language. Over time, statistical models like Hidden Markov Models (HMMs) played a crucial role, and now deep neural networks, particularly recurrent neural networks (RNNs) and convolutional neural networks (CNNs) dominate the field.\n",
    "   \n",
    "- **Computer Vision:** The evolution of computer vision techniques from simple edge detection algorithms and feature extraction methods to sophisticated deep learning models is another example. Techniques have ranged from geometric model fitting and template matching to the use of deep convolutional neural networks (CNNs) for tasks such as image classification, object detection, and semantic segmentation.\n",
    "   \n",
    "- **Game Playing:** The development of AI for game playing, from chess and checkers to complex video games, has seen strategies evolve from brute-force search algorithms and heuristic-based approaches to the use of machine learning techniques, including reinforcement learning and deep learning for strategy optimization.\n",
    "\n",
    "### **(B) Similarities Between Rule-based Translation Systems and Neural Systems:**\n",
    "\n",
    "Despite their differences, there are notable similarities between some aspects of rule-based translation systems and state-of-the-art neural systems:\n",
    "\n",
    "- **Structured Knowledge:** Rule-based systems are explicitly programmed with linguistic rules and dictionaries. Neural systems, particularly those employing attention mechanisms, implicitly learn to encode structured knowledge about languages through training on large datasets, creating internal representations that mirror some aspects of linguistic rules.\n",
    "\n",
    "- **Context Handling:** Both systems attempt to handle context in translation, albeit in radically different ways. Rule-based systems may use context rules to choose the correct translation of a word based on surrounding words. Neural systems, especially those using mechanisms like attention, are able to consider broader context in a more fluid and dynamic manner to understand the appropriate meaning.\n",
    "   \n",
    "- **Error Correction:** Both systems have mechanisms for error correction, although neural systems do this implicitly. Rule-based systems may use post-processing rules to correct common mistakes, while neural systems learn error patterns and their corrections during training.\n",
    "\n",
    "### **(C) Situations Favoring Rule-based Solutions Over Modern Approaches:**\n",
    "\n",
    "There are scenarios where a rule-based solution might be preferable to a modern neural or statistical approach:\n",
    "\n",
    "- **Limited Data Scenarios:** For languages or specialized domains where there is a scarcity of training data, rule-based systems can be more practical and effective because they do not require large datasets to perform reasonably well.\n",
    "   \n",
    "- **Predictability and Transparency:** In situations where predictability, transparency, and the ability to audit or explain decisions are crucial (e.g., in some legal or regulatory contexts), rule-based systems offer clear advantages. Their decisions are based on explicit rules that can be examined, understood, and modified by humans.\n",
    "\n",
    "- **Real-time Constraints:** In cases where computational resources are limited or real-time performance is essential, the relative simplicity and lower computational requirements of rule-based systems can be an advantage over more resource-intensive neural models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6dbabbbd02376",
   "metadata": {
    "id": "b1b6dbabbbd02376"
   },
   "source": [
    "## Problem 2: Implementation\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (A) Warmup: Word Frequencies\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2344500c97686b5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              German  \\\n",
      "0  ich erkläre die am freitag , dem 17. dezember ...   \n",
      "1  wie sie feststellen konnten , ist der gefürcht...   \n",
      "2  im parlament besteht der wunsch nach einer aus...   \n",
      "3  heute möchte ich sie bitten - das ist auch der...   \n",
      "4  wie sie sicher aus der presse und dem fernsehe...   \n",
      "\n",
      "                                          English_DE  \n",
      "0  i declare resumed the session of the european ...  \n",
      "1  although , as you will have seen , the dreaded...  \n",
      "2  you have requested a debate on this subject in...  \n",
      "3  in the meantime , i should like to observe a m...  \n",
      "4  you will be aware from the press and televisio...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets into DataFrames\n",
    "de_en_df = pd.DataFrame({\n",
    "    'German': pd.read_csv(\"dat410_europarl/europarl-v7.de-en.lc.de\", sep='\\n', header=None, names=['text'], squeeze=True),\n",
    "    'English_DE': pd.read_csv(\"dat410_europarl/europarl-v7.de-en.lc.en\", sep='\\n', header=None, names=['text'], squeeze=True)\n",
    "})\n",
    "\n",
    "fr_en_df = pd.DataFrame({\n",
    "    'French': pd.read_csv(\"dat410_europarl/europarl-v7.fr-en.lc.fr\", sep='\\n', header=None, names=['text'], squeeze=True),\n",
    "    'English_FR': pd.read_csv(\"dat410_europarl/europarl-v7.fr-en.lc.en\", sep='\\n', header=None, names=['text'], squeeze=True)\n",
    "})\n",
    "\n",
    "sv_en_df = pd.DataFrame({\n",
    "    'Swedish': pd.read_csv(\"dat410_europarl/europarl-v7.sv-en.lc.sv\", sep='\\n', header=None, names=['text'], squeeze=True),\n",
    "    'English_SV': pd.read_csv(\"dat410_europarl/europarl-v7.sv-en.lc.en\", sep='\\n', header=None, names=['text'], squeeze=True)\n",
    "})\n",
    "\n",
    "# Display the first few rows of the German-English dataset\n",
    "print(de_en_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:02.554153200Z",
     "start_time": "2024-02-19T22:18:02.382100700Z"
    }
   },
   "id": "817613a5b9b4d9cb",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              French  \\\n",
      "0  je déclare reprise la session du parlement eur...   \n",
      "1  comme vous avez pu le constater , le grand &qu...   \n",
      "2  vous avez souhaité un débat à ce sujet dans le...   \n",
      "3  en attendant , je souhaiterais , comme un cert...   \n",
      "4  je vous invite à vous lever pour cette minute ...   \n",
      "\n",
      "                                          English_FR  \n",
      "0  i declare resumed the session of the european ...  \n",
      "1  although , as you will have seen , the dreaded...  \n",
      "2  you have requested a debate on this subject in...  \n",
      "3  in the meantime , i should like to observe a m...  \n",
      "4  please rise , then , for this minute &apos; s ...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the French-English dataset\n",
    "print(fr_en_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:02.567206600Z",
     "start_time": "2024-02-19T22:18:02.550158100Z"
    }
   },
   "id": "843e900b35ca21fe",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Swedish  \\\n",
      "0  jag förklarar europaparlamentets session återu...   \n",
      "1  som ni kunnat konstatera ägde &quot; den stora...   \n",
      "2  ni har begärt en debatt i ämnet under sammantr...   \n",
      "3  till dess vill jag att vi , som ett antal koll...   \n",
      "4             jag ber er resa er för en tyst minut .   \n",
      "\n",
      "                                          English_SV  \n",
      "0  i declare resumed the session of the european ...  \n",
      "1  although , as you will have seen , the dreaded...  \n",
      "2  you have requested a debate on this subject in...  \n",
      "3  in the meantime , i should like to observe a m...  \n",
      "4  please rise , then , for this minute &apos; s ...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the Swedish-English dataset\n",
    "print(sv_en_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:02.647961500Z",
     "start_time": "2024-02-19T22:18:02.564673Z"
    }
   },
   "id": "4d02f8867e40f6f4",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to calculate word frequencies\n",
    "def calculate_word_frequencies(df_column):\n",
    "    word_counts = Counter()\n",
    "    for text in df_column:\n",
    "        # Remove punctuation and other non-word characters\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        word_counts.update(words)\n",
    "    return word_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:02.648968400Z",
     "start_time": "2024-02-19T22:18:02.582769300Z"
    }
   },
   "id": "3c9bd61df230e8d2",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate word frequencies for each language\n",
    "de_word_counts = calculate_word_frequencies(de_en_df['German'])\n",
    "en_de_word_counts = calculate_word_frequencies(de_en_df['English_DE'])\n",
    "\n",
    "fr_word_counts = calculate_word_frequencies(fr_en_df['French'])\n",
    "en_fr_word_counts = calculate_word_frequencies(fr_en_df['English_FR'])\n",
    "\n",
    "sv_word_counts = calculate_word_frequencies(sv_en_df['Swedish'])\n",
    "en_sv_word_counts = calculate_word_frequencies(sv_en_df['English_SV'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:03.498522700Z",
     "start_time": "2024-02-19T22:18:02.597822700Z"
    }
   },
   "id": "adcf00330048fa75",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to print most common words\n",
    "def print_most_common(word_counts, language, num=10):\n",
    "    print(f\"Most common words in {language}:\")\n",
    "    for word, count in word_counts.most_common(num):\n",
    "        print(f\"{word}: {count}\")\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:03.519601400Z",
     "start_time": "2024-02-19T22:18:03.501520500Z"
    }
   },
   "id": "c66efd3074499963",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in German:\n",
      "die: 10521\n",
      "der: 9374\n",
      "und: 7028\n",
      "in: 4175\n",
      "zu: 3169\n",
      "den: 2976\n",
      "wir: 2863\n",
      "daß: 2738\n",
      "ich: 2670\n",
      "das: 2669\n",
      "\n",
      "\n",
      "Most common words in English (DE):\n",
      "the: 19853\n",
      "of: 9633\n",
      "to: 9069\n",
      "and: 7307\n",
      "in: 6278\n",
      "is: 4478\n",
      "that: 4441\n",
      "a: 4438\n",
      "we: 3372\n",
      "this: 3362\n",
      "\n",
      "\n",
      "Most common words in French:\n",
      "apos: 16729\n",
      "de: 14528\n",
      "la: 9746\n",
      "et: 6620\n",
      "l: 6536\n",
      "le: 6177\n",
      "à: 5588\n",
      "les: 5587\n",
      "des: 5232\n",
      "que: 4797\n",
      "\n",
      "\n",
      "Most common words in English (FR):\n",
      "the: 19627\n",
      "of: 9534\n",
      "to: 8992\n",
      "and: 7214\n",
      "in: 6197\n",
      "is: 4453\n",
      "that: 4421\n",
      "a: 4388\n",
      "we: 3341\n",
      "this: 3332\n",
      "\n",
      "\n",
      "Most common words in Swedish:\n",
      "att: 9181\n",
      "och: 7038\n",
      "i: 5954\n",
      "det: 5687\n",
      "som: 5028\n",
      "för: 4959\n",
      "av: 4013\n",
      "är: 3840\n",
      "en: 3724\n",
      "vi: 3211\n",
      "\n",
      "\n",
      "Most common words in English (SV):\n",
      "the: 19327\n",
      "of: 9344\n",
      "to: 8814\n",
      "and: 6949\n",
      "in: 6124\n",
      "is: 4400\n",
      "that: 4357\n",
      "a: 4271\n",
      "we: 3223\n",
      "this: 3222\n"
     ]
    }
   ],
   "source": [
    "# Print the 10 most frequent words for each language\n",
    "print_most_common(de_word_counts, \"German\")\n",
    "print_most_common(en_de_word_counts, \"English (DE)\")\n",
    "\n",
    "print_most_common(fr_word_counts, \"French\")\n",
    "print_most_common(en_fr_word_counts, \"English (FR)\")\n",
    "\n",
    "print_most_common(sv_word_counts, \"Swedish\")\n",
    "print_most_common(en_sv_word_counts, \"English (SV)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:03.545121100Z",
     "start_time": "2024-02-19T22:18:03.516586900Z"
    }
   },
   "id": "1c678acf838a13c",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'speaker' in German: 0.000000\n",
      "Probability of 'zebra' in German: 0.000000\n",
      "Probability of 'speaker' in English (DE): 0.000042\n",
      "Probability of 'zebra' in English (DE): 0.000000\n",
      "Probability of 'speaker' in French: 0.000000\n",
      "Probability of 'zebra' in French: 0.000000\n",
      "Probability of 'speaker' in English (FR): 0.000046\n",
      "Probability of 'zebra' in English (FR): 0.000000\n",
      "Probability of 'speaker' in Swedish: 0.000000\n",
      "Probability of 'zebra' in Swedish: 0.000000\n",
      "Probability of 'speaker' in English (SV): 0.000039\n",
      "Probability of 'zebra' in English (SV): 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print probabilities for 'speaker' and 'zebra' in each language\n",
    "def print_probabilities(word_counts, language, total_words):\n",
    "    for word in ['speaker', 'zebra']:\n",
    "        prob = word_counts[word] / total_words if word in word_counts else 0\n",
    "        print(f\"Probability of '{word}' in {language}: {prob:.6f}\")\n",
    "\n",
    "total_de_words = sum(de_word_counts.values())\n",
    "total_en_de_words = sum(en_de_word_counts.values())\n",
    "total_fr_words = sum(fr_word_counts.values())\n",
    "total_en_fr_words = sum(en_fr_word_counts.values())\n",
    "total_sv_words = sum(sv_word_counts.values())\n",
    "total_en_sv_words = sum(en_sv_word_counts.values())\n",
    "\n",
    "print_probabilities(de_word_counts, \"German\", total_de_words)\n",
    "print_probabilities(en_de_word_counts, \"English (DE)\", total_en_de_words)\n",
    "print_probabilities(fr_word_counts, \"French\", total_fr_words)\n",
    "print_probabilities(en_fr_word_counts, \"English (FR)\", total_en_fr_words)\n",
    "print_probabilities(sv_word_counts, \"Swedish\", total_sv_words)\n",
    "print_probabilities(en_sv_word_counts, \"English (SV)\", total_en_sv_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:03.574976800Z",
     "start_time": "2024-02-19T22:18:03.550723500Z"
    }
   },
   "id": "2616bdd5e8d0c0ba",
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "### (B) Language Modeling\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "603802a163b48ed7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence 'The economic impact of the legislation was significant.' in German-English data: 5.452363580933155e-28\n",
      "Probability of the sentence 'Diplomatic efforts were intensified to resolve the conflict.' in French-English data: 5.274458597849841e-34\n",
      "Probability of the sentence 'Environmental policies have become increasingly important.' in Swedish-English data: 1.381206394015978e-26\n",
      "Probability of the sentence with an OOV word 'this is a quixotic test sentence' in German-English data: 1.0607721443308697e-21\n",
      "Probability of the sentence with an OOV word 'this is a quixotic test sentence' in French-English data: 1.002015313026314e-21\n",
      "Probability of the sentence with an OOV word 'this is a quixotic test sentence' in Swedish-English data: 9.95057646378109e-22\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text and add start and end tokens\n",
    "tokenized_text_de = [('<START>',) + tuple(re.findall(r'\\b\\w+\\b', sentence.lower())) + ('<END>',) for sentence in de_en_df['English_DE']]\n",
    "tokenized_text_fr = [('<START>',) + tuple(re.findall(r'\\b\\w+\\b', sentence.lower())) + ('<END>',) for sentence in fr_en_df['English_FR']]\n",
    "tokenized_text_sv = [('<START>',) + tuple(re.findall(r'\\b\\w+\\b', sentence.lower())) + ('<END>',) for sentence in sv_en_df['English_SV']]\n",
    "\n",
    "# Count individual words and bigrams\n",
    "word_counts_de = Counter()\n",
    "bigram_counts_de = Counter()\n",
    "word_counts_fr = Counter()\n",
    "bigram_counts_fr = Counter()\n",
    "word_counts_sv = Counter()\n",
    "bigram_counts_sv = Counter()\n",
    "\n",
    "for sentence in tokenized_text_de:\n",
    "    word_counts_de.update(sentence)\n",
    "    bigram_counts_de.update(zip(sentence[:-1], sentence[1:]))\n",
    "\n",
    "for sentence in tokenized_text_fr:\n",
    "    word_counts_fr.update(sentence)\n",
    "    bigram_counts_fr.update(zip(sentence[:-1], sentence[1:]))\n",
    "\n",
    "for sentence in tokenized_text_sv:\n",
    "    word_counts_sv.update(sentence)\n",
    "    bigram_counts_sv.update(zip(sentence[:-1], sentence[1:]))\n",
    "\n",
    "# Compute the probability of a sentence using a bigram model with Laplace smoothing\n",
    "def bigram_sentence_probability(sentence, word_counts, bigram_counts, total_words, smoothing=1):\n",
    "    sentence = ('<START>',) + tuple(re.findall(r'\\b\\w+\\b', sentence.lower())) + ('<END>',)\n",
    "    bigram_probs = []\n",
    "\n",
    "    for first_word, second_word in zip(sentence[:-1], sentence[1:]):\n",
    "        bigram_count = bigram_counts[(first_word, second_word)]\n",
    "        word_count = word_counts[first_word]\n",
    "        # Apply Laplace smoothing\n",
    "        prob = (bigram_count + smoothing) / (word_count + smoothing * (total_words + 1))\n",
    "        bigram_probs.append(prob)\n",
    "\n",
    "    # Use logarithms to avoid underflow with long sentences\n",
    "    log_probs = np.log(bigram_probs)\n",
    "    log_prob_sentence = np.sum(log_probs)\n",
    "\n",
    "    return np.exp(log_prob_sentence)\n",
    "\n",
    "# Test the bigram_sentence_probability function with sample sentences for the German-English dataset\n",
    "de_sentence = \"The economic impact of the legislation was significant.\"\n",
    "de_prob = bigram_sentence_probability(de_sentence, word_counts_de, bigram_counts_de, len(word_counts_de))\n",
    "print(f\"Probability of the sentence '{de_sentence}' in German-English data: {de_prob}\")\n",
    "\n",
    "# Test the bigram_sentence_probability function with sample sentences for the French-English dataset\n",
    "fr_sentence = \"Diplomatic efforts were intensified to resolve the conflict.\"\n",
    "fr_prob = bigram_sentence_probability(fr_sentence, word_counts_fr, bigram_counts_fr, len(word_counts_fr))\n",
    "print(f\"Probability of the sentence '{fr_sentence}' in French-English data: {fr_prob}\")\n",
    "\n",
    "# Test the bigram_sentence_probability function with sample sentences for the Swedish-English dataset\n",
    "sv_sentence = \"Environmental policies have become increasingly important.\"\n",
    "sv_prob = bigram_sentence_probability(sv_sentence, word_counts_sv, bigram_counts_sv, len(word_counts_sv))\n",
    "print(f\"Probability of the sentence '{sv_sentence}' in Swedish-English data: {sv_prob}\")\n",
    "\n",
    "# OOV word test\n",
    "oov_sentence = \"this is a quixotic test sentence\"\n",
    "oov_prob_de = bigram_sentence_probability(oov_sentence, word_counts_de, bigram_counts_de, len(word_counts))\n",
    "oov_prob_fr = bigram_sentence_probability(oov_sentence, word_counts_fr, bigram_counts_fr, len(word_counts))\n",
    "oov_prob_sv = bigram_sentence_probability(oov_sentence, word_counts_sv, bigram_counts_sv, len(word_counts))\n",
    "print(f\"Probability of the sentence with an OOV word '{oov_sentence}' in German-English data: {oov_prob_de}\")\n",
    "print(f\"Probability of the sentence with an OOV word '{oov_sentence}' in French-English data: {oov_prob_fr}\")\n",
    "print(f\"Probability of the sentence with an OOV word '{oov_sentence}' in Swedish-English data: {oov_prob_sv}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T22:18:04.362606500Z",
     "start_time": "2024-02-19T22:18:03.623821700Z"
    }
   },
   "id": "b3af9522c34a79e7",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Problem 3: Discussion\n",
    "***"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abc48290c4db11b3"
  },
  {
   "cell_type": "markdown",
   "id": "88753424",
   "metadata": {},
   "source": [
    "## References\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c902e53e01be6b5",
   "metadata": {
    "id": "3c902e53e01be6b5"
   },
   "source": [
    "## Self Check\n",
    "***\n",
    "- Have you answered all questions to the best of your ability?\n",
    "Yes, we have.\n",
    "- Is all the required information on the front page, is the file name correct etc.?\n",
    "Indeed, all the required information on the front page has been included.\n",
    "- Anything else you can easily check? (details, terminology, arguments, clearly stated answers etc.?)\n",
    "We have checked, and everything looks good."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
